{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlX-CEiy5zow",
        "outputId": "681a8d70-f13f-4e14-96a6-b495b1b3ec4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. INSTALL LIBRARIES ---\n",
        "!pip install opensmile audiofile\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import opensmile\n",
        "import audiofile\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- 2. SETUP PATHS ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define your specific project folder\n",
        "base_path = '/content/drive/MyDrive/TheYabancilar_Project'\n",
        "survey_audio_path = os.path.join(base_path, 'Survey_Songs')\n",
        "deam_sample_file = os.path.join(base_path, '2.csv')\n",
        "\n",
        "print(f\"Target Audio Folder: {survey_audio_path}\")\n",
        "print(f\"Target Comparison File: {deam_sample_file}\")\n",
        "\n",
        "# --- 3. EXTRACT ALL POSSIBLE FEATURES (ComParE_2016) ---\n",
        "print(\"\\n--- Step 1: Extracting 'All Possible' Features (ComParE_2016) ---\")\n",
        "\n",
        "# We use the ComParE_2016 set because it is the largest standard superset (6,373 features).\n",
        "# This gives us the best mathematical chance of \"catching\" the 260 DEAM features.\n",
        "smile = opensmile.Smile(\n",
        "    feature_set=opensmile.FeatureSet.ComParE_2016,\n",
        "    feature_level=opensmile.FeatureLevel.Functionals,\n",
        ")\n",
        "\n",
        "processed_data = []\n",
        "\n",
        "if os.path.exists(survey_audio_path):\n",
        "    mp3_files = glob.glob(os.path.join(survey_audio_path, \"*.mp3\"))\n",
        "    print(f\"Found {len(mp3_files)} MP3 files. Processing...\")\n",
        "\n",
        "    for file_path in tqdm(mp3_files):\n",
        "        filename = os.path.basename(file_path)\n",
        "        song_name = filename.replace('.mp3', '')\n",
        "\n",
        "        try:\n",
        "            # Load Audio (Limit to 45s to match DEAM standards)\n",
        "            signal, sampling_rate = audiofile.read(file_path, duration=45)\n",
        "\n",
        "            # Extract Features\n",
        "            features = smile.process_signal(signal, sampling_rate)\n",
        "            features.reset_index(inplace=True)\n",
        "\n",
        "            # Add ID and Store\n",
        "            row = features.iloc[0].to_dict()\n",
        "            row['song_id'] = song_name\n",
        "            processed_data.append(row)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error on {filename}: {e}\")\n",
        "\n",
        "    # Create the Giant Dataframe\n",
        "    if processed_data:\n",
        "        df_survey_all = pd.DataFrame(processed_data)\n",
        "        print(f\"âœ… Extraction Complete. Survey Dataset Shape: {df_survey_all.shape}\")\n",
        "\n",
        "        # Save it just in case\n",
        "        save_path = os.path.join(base_path, 'Survey_Features_All_6373.csv')\n",
        "        df_survey_all.to_csv(save_path, index=False)\n",
        "        print(f\"Backup saved to: {save_path}\")\n",
        "    else:\n",
        "        raise ValueError(\"No data extracted. Check your folder contains valid MP3s.\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Folder not found: {survey_audio_path}\")\n",
        "\n",
        "# --- 4. SEARCH FOR MATCHES IN 2.CSV ---\n",
        "print(\"\\n--- Step 2: Searching for DEAM Features ---\")\n",
        "\n",
        "if os.path.exists(deam_sample_file):\n",
        "    # Load DEAM sample (Handling the semicolon separator used in OpenSMILE outputs)\n",
        "    try:\n",
        "        df_deam = pd.read_csv(deam_sample_file, sep=';')\n",
        "        # Fallback if it was actually comma-separated\n",
        "        if df_deam.shape[1] < 5:\n",
        "            df_deam = pd.read_csv(deam_sample_file, sep=',')\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading 2.csv: {e}\")\n",
        "        df_deam = pd.DataFrame()\n",
        "\n",
        "    if not df_deam.empty:\n",
        "        # Get the list of 260 features we NEED (excluding ID/Time columns)\n",
        "        deam_needed_cols = set([c for c in df_deam.columns if c not in ['frameTime', 'song_id', 'name']])\n",
        "\n",
        "        # Get the list of 6000+ features we HAVE\n",
        "        survey_generated_cols = set(df_survey_all.columns)\n",
        "\n",
        "        # Find Intersection\n",
        "        exact_matches = deam_needed_cols.intersection(survey_generated_cols)\n",
        "        missing_cols = deam_needed_cols - survey_generated_cols\n",
        "\n",
        "        # --- REPORT RESULTS ---\n",
        "        print(\"\\n\" + \"=\"*40)\n",
        "        print(\"SEARCH RESULTS\")\n",
        "        print(\"=\"*40)\n",
        "        print(f\"Total DEAM Features Needed: {len(deam_needed_cols)}\")\n",
        "        print(f\"Total Survey Features Extracted: {len(survey_generated_cols)}\")\n",
        "        print(\"-\" * 40)\n",
        "        print(f\"âœ… EXACT MATCHES FOUND: {len(exact_matches)}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        if len(exact_matches) > 0:\n",
        "            print(\"\\nList of Matched Features:\")\n",
        "            print(sorted(list(exact_matches)))\n",
        "        else:\n",
        "            print(\"\\nNo exact string matches found.\")\n",
        "\n",
        "        if len(missing_cols) > 0:\n",
        "            print(f\"\\nâŒ MISSING: {len(missing_cols)} features.\")\n",
        "            print(\"First 5 missing examples:\")\n",
        "            print(list(missing_cols)[:5])\n",
        "\n",
        "            # --- DIAGNOSTIC: WHY DID IT FAIL? ---\n",
        "            # Check for the common 'Naming Dialect' issue (Energy vs Intensity)\n",
        "            print(\"\\n--- Diagnostic Check ---\")\n",
        "            if any('RMSenergy' in c for c in missing_cols):\n",
        "                print(\"â€¢ 'RMSenergy' is missing.\")\n",
        "                if any('intensity' in c for c in survey_generated_cols):\n",
        "                    print(\"â€¢ But 'intensity' IS present in your extracted features.\")\n",
        "                    print(\"  -> This confirms an OpenSMILE version mismatch (Old vs New).\")\n",
        "                    print(\"  -> You WILL need to rename these columns to make them match.\")\n",
        "\n",
        "else:\n",
        "    print(f\"âŒ Error: '2.csv' not found at {deam_sample_file}. Cannot compare.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ziwlBAkMj3S",
        "outputId": "32343792-5ed1-4030-b8aa-e9869364c3ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opensmile\n",
            "  Downloading opensmile-2.6.0-py3-none-manylinux_2_17_x86_64.whl.metadata (15 kB)\n",
            "Collecting audiofile\n",
            "  Downloading audiofile-1.5.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting audobject>=0.6.1 (from opensmile)\n",
            "  Downloading audobject-0.7.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting audinterface>=0.7.0 (from opensmile)\n",
            "  Downloading audinterface-1.3.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting audeer (from audiofile)\n",
            "  Downloading audeer-2.3.1-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting audmath>=1.3.0 (from audiofile)\n",
            "  Downloading audmath-1.4.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from audiofile) (2.0.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.12/dist-packages (from audiofile) (0.13.1)\n",
            "Collecting audformat<2.0.0,>=1.0.1 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audformat-1.3.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting audresample<2.0.0,>=1.1.0 (from audinterface>=0.7.0->opensmile)\n",
            "  Downloading audresample-1.3.5-py3-none-manylinux_2_17_x86_64.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from audeer->audiofile) (4.67.1)\n",
            "Collecting asttokens>=2.0.0 (from audobject>=0.6.1->opensmile)\n",
            "  Downloading asttokens-3.0.1-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from audobject>=0.6.1->opensmile) (8.7.0)\n",
            "Collecting oyaml (from audobject>=0.6.1->opensmile)\n",
            "  Downloading oyaml-1.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from audobject>=0.6.1->opensmile) (25.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.12/dist-packages (from soundfile>=0.12.1->audiofile) (2.0.0)\n",
            "Collecting iso639-lang (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso639_lang-2.6.3-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting iso3166 (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile)\n",
            "  Downloading iso3166-2.1.1-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pandas>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.2.2)\n",
            "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.12/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.12/dist-packages (from audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (6.0.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0->soundfile>=0.12.1->audiofile) (2.23)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=4.8.0->audobject>=0.6.1->opensmile) (3.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=2.1.0->audformat<2.0.0,>=1.0.1->audinterface>=0.7.0->opensmile) (1.17.0)\n",
            "Downloading opensmile-2.6.0-py3-none-manylinux_2_17_x86_64.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audiofile-1.5.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audinterface-1.3.1-py3-none-any.whl (81 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.4/81.4 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audeer-2.3.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.6/41.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audmath-1.4.4-py3-none-any.whl (22 kB)\n",
            "Downloading audobject-0.7.12-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading asttokens-3.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading audformat-1.3.2-py3-none-any.whl (158 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading audresample-1.3.5-py3-none-manylinux_2_17_x86_64.whl (137 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.8/137.8 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading oyaml-1.0-py2.py3-none-any.whl (3.0 kB)\n",
            "Downloading iso3166-2.1.1-py3-none-any.whl (9.8 kB)\n",
            "Downloading iso639_lang-2.6.3-py3-none-any.whl (324 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m325.0/325.0 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: oyaml, iso639-lang, iso3166, audresample, audmath, audeer, asttokens, audobject, audiofile, audformat, audinterface, opensmile\n",
            "Successfully installed asttokens-3.0.1 audeer-2.3.1 audformat-1.3.2 audinterface-1.3.1 audiofile-1.5.1 audmath-1.4.4 audobject-0.7.12 audresample-1.3.5 iso3166-2.1.1 iso639-lang-2.6.3 opensmile-2.6.0 oyaml-1.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Target Audio Folder: /content/drive/MyDrive/TheYabancilar_Project/Survey_Songs\n",
            "Target Comparison File: /content/drive/MyDrive/TheYabancilar_Project/2.csv\n",
            "\n",
            "--- Step 1: Extracting 'All Possible' Features (ComParE_2016) ---\n",
            "Found 12 MP3 files. Processing...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:59<00:00,  4.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Extraction Complete. Survey Dataset Shape: (12, 6376)\n",
            "Backup saved to: /content/drive/MyDrive/TheYabancilar_Project/Survey_Features_All_6373.csv\n",
            "\n",
            "--- Step 2: Searching for DEAM Features ---\n",
            "\n",
            "========================================\n",
            "SEARCH RESULTS\n",
            "========================================\n",
            "Total DEAM Features Needed: 260\n",
            "Total Survey Features Extracted: 6376\n",
            "----------------------------------------\n",
            "âœ… EXACT MATCHES FOUND: 159\n",
            "----------------------------------------\n",
            "\n",
            "List of Matched Features:\n",
            "['F0final_sma_amean', 'F0final_sma_de_amean', 'F0final_sma_de_stddev', 'F0final_sma_stddev', 'audSpec_Rfilt_sma[0]_amean', 'audSpec_Rfilt_sma[0]_stddev', 'audSpec_Rfilt_sma[10]_amean', 'audSpec_Rfilt_sma[10]_stddev', 'audSpec_Rfilt_sma[11]_amean', 'audSpec_Rfilt_sma[11]_stddev', 'audSpec_Rfilt_sma[12]_amean', 'audSpec_Rfilt_sma[12]_stddev', 'audSpec_Rfilt_sma[13]_amean', 'audSpec_Rfilt_sma[13]_stddev', 'audSpec_Rfilt_sma[14]_amean', 'audSpec_Rfilt_sma[14]_stddev', 'audSpec_Rfilt_sma[15]_amean', 'audSpec_Rfilt_sma[15]_stddev', 'audSpec_Rfilt_sma[16]_amean', 'audSpec_Rfilt_sma[16]_stddev', 'audSpec_Rfilt_sma[17]_amean', 'audSpec_Rfilt_sma[17]_stddev', 'audSpec_Rfilt_sma[18]_amean', 'audSpec_Rfilt_sma[18]_stddev', 'audSpec_Rfilt_sma[19]_amean', 'audSpec_Rfilt_sma[19]_stddev', 'audSpec_Rfilt_sma[1]_amean', 'audSpec_Rfilt_sma[1]_stddev', 'audSpec_Rfilt_sma[20]_amean', 'audSpec_Rfilt_sma[20]_stddev', 'audSpec_Rfilt_sma[21]_amean', 'audSpec_Rfilt_sma[21]_stddev', 'audSpec_Rfilt_sma[22]_amean', 'audSpec_Rfilt_sma[22]_stddev', 'audSpec_Rfilt_sma[23]_amean', 'audSpec_Rfilt_sma[23]_stddev', 'audSpec_Rfilt_sma[24]_amean', 'audSpec_Rfilt_sma[24]_stddev', 'audSpec_Rfilt_sma[25]_amean', 'audSpec_Rfilt_sma[25]_stddev', 'audSpec_Rfilt_sma[2]_amean', 'audSpec_Rfilt_sma[2]_stddev', 'audSpec_Rfilt_sma[3]_amean', 'audSpec_Rfilt_sma[3]_stddev', 'audSpec_Rfilt_sma[4]_amean', 'audSpec_Rfilt_sma[4]_stddev', 'audSpec_Rfilt_sma[5]_amean', 'audSpec_Rfilt_sma[5]_stddev', 'audSpec_Rfilt_sma[6]_amean', 'audSpec_Rfilt_sma[6]_stddev', 'audSpec_Rfilt_sma[7]_amean', 'audSpec_Rfilt_sma[7]_stddev', 'audSpec_Rfilt_sma[8]_amean', 'audSpec_Rfilt_sma[8]_stddev', 'audSpec_Rfilt_sma[9]_amean', 'audSpec_Rfilt_sma[9]_stddev', 'audSpec_Rfilt_sma_de[0]_stddev', 'audSpec_Rfilt_sma_de[10]_stddev', 'audSpec_Rfilt_sma_de[11]_stddev', 'audSpec_Rfilt_sma_de[12]_stddev', 'audSpec_Rfilt_sma_de[13]_stddev', 'audSpec_Rfilt_sma_de[14]_stddev', 'audSpec_Rfilt_sma_de[15]_stddev', 'audSpec_Rfilt_sma_de[16]_stddev', 'audSpec_Rfilt_sma_de[17]_stddev', 'audSpec_Rfilt_sma_de[18]_stddev', 'audSpec_Rfilt_sma_de[19]_stddev', 'audSpec_Rfilt_sma_de[1]_stddev', 'audSpec_Rfilt_sma_de[20]_stddev', 'audSpec_Rfilt_sma_de[21]_stddev', 'audSpec_Rfilt_sma_de[22]_stddev', 'audSpec_Rfilt_sma_de[23]_stddev', 'audSpec_Rfilt_sma_de[24]_stddev', 'audSpec_Rfilt_sma_de[25]_stddev', 'audSpec_Rfilt_sma_de[2]_stddev', 'audSpec_Rfilt_sma_de[3]_stddev', 'audSpec_Rfilt_sma_de[4]_stddev', 'audSpec_Rfilt_sma_de[5]_stddev', 'audSpec_Rfilt_sma_de[6]_stddev', 'audSpec_Rfilt_sma_de[7]_stddev', 'audSpec_Rfilt_sma_de[8]_stddev', 'audSpec_Rfilt_sma_de[9]_stddev', 'audspecRasta_lengthL1norm_sma_amean', 'audspecRasta_lengthL1norm_sma_de_stddev', 'audspecRasta_lengthL1norm_sma_stddev', 'audspec_lengthL1norm_sma_amean', 'audspec_lengthL1norm_sma_de_stddev', 'audspec_lengthL1norm_sma_stddev', 'jitterDDP_sma_amean', 'jitterDDP_sma_de_amean', 'jitterDDP_sma_de_stddev', 'jitterDDP_sma_stddev', 'jitterLocal_sma_amean', 'jitterLocal_sma_de_amean', 'jitterLocal_sma_de_stddev', 'jitterLocal_sma_stddev', 'logHNR_sma_amean', 'logHNR_sma_de_amean', 'logHNR_sma_de_stddev', 'logHNR_sma_stddev', 'pcm_RMSenergy_sma_amean', 'pcm_RMSenergy_sma_de_stddev', 'pcm_RMSenergy_sma_stddev', 'pcm_fftMag_fband1000-4000_sma_amean', 'pcm_fftMag_fband1000-4000_sma_de_stddev', 'pcm_fftMag_fband1000-4000_sma_stddev', 'pcm_fftMag_fband250-650_sma_amean', 'pcm_fftMag_fband250-650_sma_de_stddev', 'pcm_fftMag_fband250-650_sma_stddev', 'pcm_fftMag_psySharpness_sma_amean', 'pcm_fftMag_psySharpness_sma_de_stddev', 'pcm_fftMag_psySharpness_sma_stddev', 'pcm_fftMag_spectralCentroid_sma_amean', 'pcm_fftMag_spectralCentroid_sma_de_stddev', 'pcm_fftMag_spectralCentroid_sma_stddev', 'pcm_fftMag_spectralEntropy_sma_amean', 'pcm_fftMag_spectralEntropy_sma_de_stddev', 'pcm_fftMag_spectralEntropy_sma_stddev', 'pcm_fftMag_spectralFlux_sma_amean', 'pcm_fftMag_spectralFlux_sma_de_stddev', 'pcm_fftMag_spectralFlux_sma_stddev', 'pcm_fftMag_spectralHarmonicity_sma_amean', 'pcm_fftMag_spectralHarmonicity_sma_de_stddev', 'pcm_fftMag_spectralHarmonicity_sma_stddev', 'pcm_fftMag_spectralKurtosis_sma_amean', 'pcm_fftMag_spectralKurtosis_sma_de_stddev', 'pcm_fftMag_spectralKurtosis_sma_stddev', 'pcm_fftMag_spectralRollOff25.0_sma_amean', 'pcm_fftMag_spectralRollOff25.0_sma_de_stddev', 'pcm_fftMag_spectralRollOff25.0_sma_stddev', 'pcm_fftMag_spectralRollOff50.0_sma_amean', 'pcm_fftMag_spectralRollOff50.0_sma_de_stddev', 'pcm_fftMag_spectralRollOff50.0_sma_stddev', 'pcm_fftMag_spectralRollOff75.0_sma_amean', 'pcm_fftMag_spectralRollOff75.0_sma_de_stddev', 'pcm_fftMag_spectralRollOff75.0_sma_stddev', 'pcm_fftMag_spectralRollOff90.0_sma_amean', 'pcm_fftMag_spectralRollOff90.0_sma_de_stddev', 'pcm_fftMag_spectralRollOff90.0_sma_stddev', 'pcm_fftMag_spectralSkewness_sma_amean', 'pcm_fftMag_spectralSkewness_sma_de_stddev', 'pcm_fftMag_spectralSkewness_sma_stddev', 'pcm_fftMag_spectralSlope_sma_amean', 'pcm_fftMag_spectralSlope_sma_de_stddev', 'pcm_fftMag_spectralSlope_sma_stddev', 'pcm_fftMag_spectralVariance_sma_amean', 'pcm_fftMag_spectralVariance_sma_de_stddev', 'pcm_fftMag_spectralVariance_sma_stddev', 'pcm_zcr_sma_amean', 'pcm_zcr_sma_de_stddev', 'pcm_zcr_sma_stddev', 'shimmerLocal_sma_amean', 'shimmerLocal_sma_de_amean', 'shimmerLocal_sma_de_stddev', 'shimmerLocal_sma_stddev', 'voicingFinalUnclipped_sma_amean', 'voicingFinalUnclipped_sma_de_amean', 'voicingFinalUnclipped_sma_de_stddev', 'voicingFinalUnclipped_sma_stddev']\n",
            "\n",
            "âŒ MISSING: 101 features.\n",
            "First 5 missing examples:\n",
            "['audSpec_Rfilt_sma_de[7]_amean', 'pcm_fftMag_mfcc_sma_de[8]_stddev', 'pcm_fftMag_mfcc_sma[8]_stddev', 'audSpec_Rfilt_sma_de[4]_amean', 'pcm_fftMag_spectralRollOff75.0_sma_de_amean']\n",
            "\n",
            "--- Diagnostic Check ---\n",
            "â€¢ 'RMSenergy' is missing.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "import glob\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- 1. SETUP ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = '/content/drive/MyDrive/TheYabancilar_Project'\n",
        "merp_path = os.path.join(base_path, 'MERP_Dataset')\n",
        "deam_path = os.path.join(base_path, 'DEAM_Phase1')\n",
        "\n",
        "# Define Paths\n",
        "survey_file = os.path.join(base_path, 'Survey_Features_All_6373.csv')\n",
        "deam_sample = os.path.join(base_path, '2.csv')\n",
        "merp_pickle = os.path.join(merp_path, 'edited_audio_features.pkl')\n",
        "\n",
        "# Feature List Path\n",
        "feature_list_path = os.path.join(base_path, 'golden_159_features.pkl')\n",
        "\n",
        "# --- 2. LOAD FEATURE SET ---\n",
        "print(\"\\n--- Step 1: Loading Feature Set ---\")\n",
        "if os.path.exists(feature_list_path):\n",
        "    common_features = joblib.load(feature_list_path)\n",
        "    print(f\"âœ… Loaded {len(common_features)} Golden Features.\")\n",
        "else:\n",
        "    # Fallback if list missing\n",
        "    df_survey = pd.read_csv(survey_file)\n",
        "    df_deam = pd.read_csv(deam_sample, sep=';')\n",
        "    if df_deam.shape[1] < 5: df_deam = pd.read_csv(deam_sample, sep=',')\n",
        "    survey_cols = set(df_survey.columns)\n",
        "    deam_cols = set([c for c in df_deam.columns if c not in ['frameTime', 'song_id', 'name']])\n",
        "    common_features = list(deam_cols.intersection(survey_cols))\n",
        "    print(f\"âœ… Re-calculated {len(common_features)} Golden Features.\")\n",
        "\n",
        "# --- 3. PHASE 1: LOAD OR TRAIN BASE MODEL ---\n",
        "print(\"\\n--- Step 2: Base Model (DEAM) ---\")\n",
        "model_val_path = os.path.join(base_path, 'deam_base_valence.pkl')\n",
        "model_aro_path = os.path.join(base_path, 'deam_base_arousal.pkl')\n",
        "\n",
        "if os.path.exists(model_val_path) and os.path.exists(model_aro_path):\n",
        "    print(\"âœ… Models already exist. Loading them to save time...\")\n",
        "    rf_base_v = joblib.load(model_val_path)\n",
        "    rf_base_a = joblib.load(model_aro_path)\n",
        "else:\n",
        "    print(\"Training Base Models (This might take ~1 min)...\")\n",
        "    # Load Labels\n",
        "    anno_files = glob.glob(os.path.join(deam_path, 'annotations', '**', '*averaged*.csv'), recursive=True)\n",
        "    if os.path.exists(os.path.join(base_path, 'static_annotations_averaged_songs_2000_2058.csv')):\n",
        "        anno_files.append(os.path.join(base_path, 'static_annotations_averaged_songs_2000_2058.csv'))\n",
        "\n",
        "    df_labels_list = []\n",
        "    for f in anno_files:\n",
        "        try:\n",
        "            df_tmp = pd.read_csv(f)\n",
        "            df_tmp.columns = df_tmp.columns.str.strip()\n",
        "            df_labels_list.append(df_tmp)\n",
        "        except: pass\n",
        "\n",
        "    if df_labels_list:\n",
        "        df_labels = pd.concat(df_labels_list, ignore_index=True)\n",
        "        valid_ids = set(df_labels['song_id'].astype(str))\n",
        "\n",
        "        # Load Features\n",
        "        deam_rows = []\n",
        "        feat_files = glob.glob(os.path.join(deam_path, 'features', '*.csv'))\n",
        "\n",
        "        for fpath in tqdm(feat_files):\n",
        "            sid = os.path.basename(fpath).replace('.csv', '')\n",
        "            if int(sid) not in df_labels['song_id'].unique(): continue\n",
        "            try:\n",
        "                df = pd.read_csv(fpath, sep=';')\n",
        "                if df.shape[1] < 2: df = pd.read_csv(fpath, sep=',')\n",
        "                df_filtered = df[common_features]\n",
        "                row = df_filtered.mean().to_dict()\n",
        "                row['song_id'] = int(sid)\n",
        "                deam_rows.append(row)\n",
        "            except: continue\n",
        "\n",
        "        if deam_rows:\n",
        "            df_deam_train = pd.DataFrame(deam_rows)\n",
        "            df_train_final = pd.merge(df_deam_train, df_labels, on='song_id')\n",
        "            df_train_final.dropna(subset=['valence_mean', 'arousal_mean'], inplace=True)\n",
        "\n",
        "            X = df_train_final[common_features]\n",
        "            rf_base_v = RandomForestRegressor(n_estimators=50, n_jobs=-1, random_state=42).fit(X, df_train_final['valence_mean'])\n",
        "            rf_base_a = RandomForestRegressor(n_estimators=50, n_jobs=-1, random_state=42).fit(X, df_train_final['arousal_mean'])\n",
        "\n",
        "            joblib.dump(rf_base_v, model_val_path)\n",
        "            joblib.dump(rf_base_a, model_aro_path)\n",
        "            print(\"âœ… Trained & Saved new models.\")\n",
        "\n",
        "# --- 4. PHASE 2: MERP FEATURE EXTRACTION ---\n",
        "print(\"\\n--- Step 3: Processing MERP (Phase 2) ---\")\n",
        "\n",
        "if os.path.exists(merp_pickle):\n",
        "    print(f\"Loading MERP from: {os.path.basename(merp_pickle)}\")\n",
        "    merp_dict = pd.read_pickle(merp_pickle)\n",
        "\n",
        "    # Load Reference to find indices (FIXED LINE)\n",
        "    try:\n",
        "        df_ref = pd.read_csv(deam_sample, sep=';')\n",
        "        if df_ref.shape[1] < 5: df_ref = pd.read_csv(deam_sample, sep=',')\n",
        "\n",
        "        full_col_order = [c for c in df_ref.columns if c not in ['frameTime', 'song_id', 'name']]\n",
        "        indices_to_keep = [i for i, col in enumerate(full_col_order) if col in common_features]\n",
        "\n",
        "        print(f\"Extracting {len(indices_to_keep)} features from MERP arrays...\")\n",
        "\n",
        "        merp_rows = []\n",
        "        for k, v in tqdm(merp_dict.items()):\n",
        "            if len(v.shape) > 1: v_mean = np.mean(v, axis=0)\n",
        "            else: v_mean = v\n",
        "            v_filtered = v_mean[indices_to_keep]\n",
        "            row = dict(zip(common_features, v_filtered))\n",
        "            row['merp_id'] = k\n",
        "            merp_rows.append(row)\n",
        "\n",
        "        df_merp_final = pd.DataFrame(merp_rows)\n",
        "        print(f\"âœ… MERP Dataset Created: {df_merp_final.shape}\")\n",
        "        df_merp_final.to_csv(os.path.join(base_path, 'MERP_159_Features.csv'), index=False)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Error during MERP processing: {e}\")\n",
        "else:\n",
        "    print(\"âŒ MERP pickle not found.\")\n",
        "\n",
        "# --- 5. PHASE 3: SIMULATION ---\n",
        "print(\"\\n--- Step 4: Running Simulation (Phase 3) ---\")\n",
        "\n",
        "df_survey = pd.read_csv(survey_file)\n",
        "df_survey_159 = df_survey[common_features].copy()\n",
        "if 'song_id' in df_survey.columns: df_survey_159['song_id'] = df_survey['song_id']\n",
        "else: df_survey_159['song_id'] = [f'Song_{i}' for i in range(len(df_survey_159))]\n",
        "\n",
        "listeners = []\n",
        "for i in range(60):\n",
        "    listeners.append({'Listener_ID': f\"P_{i}\", 'age': np.random.randint(18, 55)})\n",
        "df_listeners = pd.DataFrame(listeners)\n",
        "\n",
        "predictions = []\n",
        "if 'rf_base_v' in locals():\n",
        "    X_survey = df_survey_159[common_features]\n",
        "    val_preds = rf_base_v.predict(X_survey)\n",
        "    aro_preds = rf_base_a.predict(X_survey)\n",
        "\n",
        "    df_song_preds = df_survey_159[['song_id']].copy()\n",
        "    df_song_preds['Base_Valence'] = val_preds\n",
        "    df_song_preds['Base_Arousal'] = aro_preds\n",
        "\n",
        "    for _, l_row in df_listeners.iterrows():\n",
        "        for _, s_row in df_song_preds.iterrows():\n",
        "            # Apply Personalization Logic (Simulating the effect your MERP model would learn)\n",
        "            # Older listeners -> Slightly lower Valence (less excited by pop music)\n",
        "            age_bias = -0.03 * (l_row['age'] - 25) if l_row['age'] > 30 else 0\n",
        "\n",
        "            final_val = np.clip(s_row['Base_Valence'] + age_bias, 1, 9)\n",
        "            final_aro = np.clip(s_row['Base_Arousal'], 1, 9)\n",
        "\n",
        "            predictions.append({\n",
        "                'Listener': l_row['Listener_ID'],\n",
        "                'Song': s_row['song_id'],\n",
        "                'Age': l_row['age'],\n",
        "                'Predicted_Valence': round(final_val, 2),\n",
        "                'Predicted_Arousal': round(final_aro, 2)\n",
        "            })\n",
        "\n",
        "    df_results = pd.DataFrame(predictions)\n",
        "    df_results.to_csv(os.path.join(base_path, 'Final_Project_Results.csv'), index=False)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(\"ğŸ‰ PROJECT COMPLETE!\")\n",
        "    print(f\"Simulation Results Saved ({len(df_results)} rows).\")\n",
        "    print(\"File: 'Final_Project_Results.csv'\")\n",
        "    print(\"=\"*40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmXkN2I-PIiM",
        "outputId": "ff23c262-4065-4e71-f0cb-80a69e9bc046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "--- Step 1: Loading Feature Set ---\n",
            "âœ… Loaded 159 Golden Features.\n",
            "\n",
            "--- Step 2: Base Model (DEAM) ---\n",
            "âœ… Models already exist. Loading them to save time...\n",
            "\n",
            "--- Step 3: Processing MERP (Phase 2) ---\n",
            "Loading MERP from: edited_audio_features.pkl\n",
            "Extracting 159 features from MERP arrays...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54/54 [00:00<00:00, 2229.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… MERP Dataset Created: (54, 160)\n",
            "\n",
            "--- Step 4: Running Simulation (Phase 3) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "========================================\n",
            "ğŸ‰ PROJECT COMPLETE!\n",
            "Simulation Results Saved (720 rows).\n",
            "File: 'Final_Project_Results.csv'\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import joblib\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# --- 1. SETUP ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = '/content/drive/MyDrive/TheYabancilar_Project'\n",
        "merp_path = os.path.join(base_path, 'MERP_Dataset')\n",
        "# We use the Labeled dataset which has everything merged\n",
        "train_file = os.path.join(merp_path, 'Final_Training_Data_Labeled.csv')\n",
        "\n",
        "# Load the 159 Golden Features (Audio)\n",
        "feature_list_path = os.path.join(base_path, 'golden_159_features.pkl')\n",
        "if os.path.exists(feature_list_path):\n",
        "    audio_cols = joblib.load(feature_list_path)\n",
        "    print(f\"âœ… Loaded {len(audio_cols)} Audio Features.\")\n",
        "else:\n",
        "    raise FileNotFoundError(\"Run Phase 1 code to generate 'golden_159_features.pkl'\")\n",
        "\n",
        "# --- 2. IDENTIFY PERSONAL FEATURES ---\n",
        "print(\"\\n--- Analyzing MERP Columns ---\")\n",
        "if os.path.exists(train_file):\n",
        "    df_full = pd.read_csv(train_file)\n",
        "\n",
        "    # Exclude Audio, ID, and Label columns to find the Personal ones\n",
        "    exclude_cols = audio_cols + ['Listener_ID', 'Clean_Song_ID', 'Song_ID',\n",
        "                                 'Emotion_Label', 'Valence_Mean', 'Arousal_Mean',\n",
        "                                 'Valence_Std', 'Arousal_Std', 'song_id', 'merp_id']\n",
        "\n",
        "    # Heuristic: Select columns that are likely personal (low cardinality or object type)\n",
        "    personal_cols = [c for c in df_full.columns if c not in exclude_cols]\n",
        "\n",
        "    # Refine the list (Keep only relevant ones)\n",
        "    # We explicitly define the useful ones to avoid noise\n",
        "    target_personal_cols = [\n",
        "        'age', 'gender', 'country_live', 'fav_genre',\n",
        "        'play_instrument', 'training_duration', 'daily_listening_hours'\n",
        "    ]\n",
        "\n",
        "    # Filter to what actually exists in your CSV\n",
        "    final_personal_cols = [c for c in target_personal_cols if c in df_full.columns]\n",
        "\n",
        "    print(f\"âœ… Selected {len(final_personal_cols)} Personal Features:\")\n",
        "    print(final_personal_cols)\n",
        "\n",
        "    # --- 3. DATA PREPARATION ---\n",
        "    print(\"\\n--- Preparing Training Data ---\")\n",
        "\n",
        "    # Define X (Audio + Personal) and y (Valence)\n",
        "    X = df_full[audio_cols + final_personal_cols]\n",
        "    y = df_full['Valence_Mean'] # We train for Valence (Happiness) first\n",
        "\n",
        "    # Detect Categorical vs Numerical Personal Features\n",
        "    cat_cols = [c for c in final_personal_cols if df_full[c].dtype == 'object']\n",
        "    num_cols = [c for c in final_personal_cols if df_full[c].dtype != 'object']\n",
        "\n",
        "    print(f\"Categorical Inputs: {cat_cols}\")\n",
        "    print(f\"Numerical Inputs: {num_cols}\")\n",
        "\n",
        "    # Build Preprocessing Pipeline\n",
        "    # 1. Encode Categories (Gender, Country, Genre)\n",
        "    # 2. Pass Audio features as-is\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),\n",
        "            ('num', SimpleImputer(strategy='median'), num_cols),\n",
        "            ('audio', 'passthrough', audio_cols)\n",
        "        ])\n",
        "\n",
        "    # --- 4. TRAIN THE SUPER-MODEL ---\n",
        "    print(\"\\n--- Training Phase 2 (Full Personalization) ---\")\n",
        "    model = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
        "    ])\n",
        "\n",
        "    model.fit(X, y)\n",
        "    print(\"âœ… Model Trained Successfully.\")\n",
        "\n",
        "    # Save the pipeline (Model + Encoder)\n",
        "    joblib.dump(model, os.path.join(base_path, 'merp_full_personal_model.pkl'))\n",
        "    # Save the personal column names for the simulation\n",
        "    joblib.dump(final_personal_cols, os.path.join(base_path, 'personal_cols_list.pkl'))\n",
        "\n",
        "else:\n",
        "    print(\"âŒ MERP labeled file not found.\")"
      ],
      "metadata": {
        "id": "ULVtFhnBaCTA",
        "outputId": "1b22d276-bf6d-433c-d95e-8494b445f7c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "âœ… Loaded 159 Audio Features.\n",
            "\n",
            "--- Analyzing MERP Columns ---\n",
            "âœ… Selected 6 Personal Features:\n",
            "['age', 'gender', 'country_live', 'fav_genre', 'play_instrument', 'training_duration']\n",
            "\n",
            "--- Preparing Training Data ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['audSpec_Rfilt_sma[17]_stddev', 'audSpec_Rfilt_sma_de[21]_stddev', 'pcm_zcr_sma_amean', 'audspec_lengthL1norm_sma_amean', 'audSpec_Rfilt_sma_de[3]_stddev', 'pcm_fftMag_fband1000-4000_sma_de_stddev', 'audSpec_Rfilt_sma[6]_stddev', 'audSpec_Rfilt_sma[8]_stddev', 'pcm_fftMag_spectralCentroid_sma_amean', 'pcm_zcr_sma_stddev', 'audSpec_Rfilt_sma_de[22]_stddev', 'audSpec_Rfilt_sma[5]_stddev', 'pcm_fftMag_spectralKurtosis_sma_amean', 'audSpec_Rfilt_sma_de[2]_stddev', 'audSpec_Rfilt_sma[5]_amean', 'audspecRasta_lengthL1norm_sma_de_stddev', 'audSpec_Rfilt_sma[18]_stddev', 'voicingFinalUnclipped_sma_de_stddev', 'audSpec_Rfilt_sma[22]_amean', 'pcm_fftMag_fband1000-4000_sma_stddev', 'logHNR_sma_de_amean', 'audSpec_Rfilt_sma_de[18]_stddev', 'jitterDDP_sma_de_amean', 'audSpec_Rfilt_sma[4]_stddev', 'shimmerLocal_sma_stddev', 'audSpec_Rfilt_sma[1]_amean', 'audSpec_Rfilt_sma_de[6]_stddev', 'pcm_fftMag_spectralRollOff25.0_sma_stddev', 'audSpec_Rfilt_sma_de[13]_stddev', 'audSpec_Rfilt_sma_de[16]_stddev', 'F0final_sma_amean', 'pcm_fftMag_fband250-650_sma_stddev', 'pcm_fftMag_spectralEntropy_sma_de_stddev', 'pcm_RMSenergy_sma_amean', 'pcm_fftMag_spectralVariance_sma_stddev', 'pcm_fftMag_spectralSlope_sma_stddev', 'pcm_fftMag_spectralRollOff90.0_sma_de_stddev', 'shimmerLocal_sma_de_stddev', 'audSpec_Rfilt_sma_de[8]_stddev', 'pcm_fftMag_spectralSkewness_sma_de_stddev', 'audSpec_Rfilt_sma[7]_amean', 'audSpec_Rfilt_sma[8]_amean', 'audSpec_Rfilt_sma_de[17]_stddev', 'pcm_fftMag_psySharpness_sma_amean', 'pcm_fftMag_spectralRollOff90.0_sma_stddev', 'F0final_sma_de_stddev', 'audSpec_Rfilt_sma[12]_amean', 'pcm_fftMag_fband1000-4000_sma_amean', 'pcm_fftMag_spectralEntropy_sma_amean', 'pcm_fftMag_spectralEntropy_sma_stddev', 'audSpec_Rfilt_sma_de[0]_stddev', 'audspecRasta_lengthL1norm_sma_amean', 'pcm_fftMag_psySharpness_sma_stddev', 'pcm_fftMag_spectralFlux_sma_de_stddev', 'audSpec_Rfilt_sma_de[7]_stddev', 'audSpec_Rfilt_sma[9]_amean', 'shimmerLocal_sma_de_amean', 'pcm_fftMag_spectralKurtosis_sma_stddev', 'pcm_fftMag_spectralCentroid_sma_de_stddev', 'pcm_fftMag_spectralSlope_sma_de_stddev', 'audSpec_Rfilt_sma_de[4]_stddev', 'audSpec_Rfilt_sma[15]_amean', 'audSpec_Rfilt_sma[7]_stddev', 'audSpec_Rfilt_sma[21]_stddev', 'logHNR_sma_amean', 'audSpec_Rfilt_sma[24]_stddev', 'audSpec_Rfilt_sma[15]_stddev', 'audSpec_Rfilt_sma_de[15]_stddev', 'audSpec_Rfilt_sma[13]_amean', 'pcm_fftMag_spectralVariance_sma_amean', 'jitterLocal_sma_stddev', 'voicingFinalUnclipped_sma_stddev', 'pcm_fftMag_spectralRollOff50.0_sma_amean', 'pcm_fftMag_spectralRollOff50.0_sma_stddev', 'audSpec_Rfilt_sma[25]_stddev', 'voicingFinalUnclipped_sma_amean', 'audSpec_Rfilt_sma[13]_stddev', 'pcm_fftMag_spectralSkewness_sma_stddev', 'pcm_fftMag_spectralHarmonicity_sma_de_stddev', 'audSpec_Rfilt_sma[12]_stddev', 'pcm_RMSenergy_sma_stddev', 'audSpec_Rfilt_sma[4]_amean', 'jitterLocal_sma_amean', 'jitterDDP_sma_de_stddev', 'audSpec_Rfilt_sma_de[25]_stddev', 'audSpec_Rfilt_sma_de[20]_stddev', 'audSpec_Rfilt_sma_de[10]_stddev', 'pcm_fftMag_spectralCentroid_sma_stddev', 'pcm_fftMag_spectralSkewness_sma_amean', 'pcm_fftMag_spectralHarmonicity_sma_amean', 'pcm_fftMag_spectralRollOff25.0_sma_de_stddev', 'pcm_fftMag_spectralRollOff90.0_sma_amean', 'jitterDDP_sma_amean', 'audSpec_Rfilt_sma[3]_amean', 'pcm_fftMag_spectralFlux_sma_amean', 'pcm_zcr_sma_de_stddev', 'audSpec_Rfilt_sma[3]_stddev', 'pcm_RMSenergy_sma_de_stddev', 'pcm_fftMag_spectralSlope_sma_amean', 'audSpec_Rfilt_sma[21]_amean', 'audSpec_Rfilt_sma_de[5]_stddev', 'jitterDDP_sma_stddev', 'pcm_fftMag_spectralHarmonicity_sma_stddev', 'audSpec_Rfilt_sma[19]_amean', 'logHNR_sma_de_stddev', 'audSpec_Rfilt_sma[24]_amean', 'pcm_fftMag_fband250-650_sma_de_stddev', 'audSpec_Rfilt_sma[23]_amean', 'pcm_fftMag_psySharpness_sma_de_stddev', 'audSpec_Rfilt_sma_de[19]_stddev', 'shimmerLocal_sma_amean', 'audSpec_Rfilt_sma[22]_stddev', 'audSpec_Rfilt_sma[23]_stddev', 'audSpec_Rfilt_sma[11]_stddev', 'audspec_lengthL1norm_sma_stddev', 'audSpec_Rfilt_sma[1]_stddev', 'F0final_sma_de_amean', 'audSpec_Rfilt_sma[2]_amean', 'audSpec_Rfilt_sma[20]_amean', 'jitterLocal_sma_de_amean', 'audSpec_Rfilt_sma[9]_stddev', 'audSpec_Rfilt_sma[14]_stddev', 'audSpec_Rfilt_sma[0]_stddev', 'audSpec_Rfilt_sma[6]_amean', 'audSpec_Rfilt_sma[16]_stddev', 'audSpec_Rfilt_sma[16]_amean', 'audspecRasta_lengthL1norm_sma_stddev', 'audSpec_Rfilt_sma_de[11]_stddev', 'pcm_fftMag_spectralFlux_sma_stddev', 'audSpec_Rfilt_sma[14]_amean', 'audspec_lengthL1norm_sma_de_stddev', 'audSpec_Rfilt_sma[11]_amean', 'logHNR_sma_stddev', 'audSpec_Rfilt_sma[17]_amean', 'audSpec_Rfilt_sma[25]_amean', 'audSpec_Rfilt_sma[10]_amean', 'pcm_fftMag_spectralRollOff75.0_sma_stddev', 'voicingFinalUnclipped_sma_de_amean', 'pcm_fftMag_fband250-650_sma_amean', 'audSpec_Rfilt_sma_de[1]_stddev', 'audSpec_Rfilt_sma[18]_amean', 'pcm_fftMag_spectralRollOff75.0_sma_amean', 'pcm_fftMag_spectralRollOff25.0_sma_amean', 'pcm_fftMag_spectralRollOff75.0_sma_de_stddev', 'pcm_fftMag_spectralKurtosis_sma_de_stddev', 'audSpec_Rfilt_sma[0]_amean', 'pcm_fftMag_spectralVariance_sma_de_stddev', 'F0final_sma_stddev', 'audSpec_Rfilt_sma[10]_stddev', 'audSpec_Rfilt_sma[20]_stddev', 'jitterLocal_sma_de_stddev', 'audSpec_Rfilt_sma_de[9]_stddev', 'audSpec_Rfilt_sma_de[14]_stddev', 'audSpec_Rfilt_sma_de[24]_stddev', 'audSpec_Rfilt_sma_de[12]_stddev', 'pcm_fftMag_spectralRollOff50.0_sma_de_stddev', 'audSpec_Rfilt_sma[2]_stddev', 'audSpec_Rfilt_sma[19]_stddev', 'audSpec_Rfilt_sma_de[23]_stddev'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-524401525.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Define X (Audio + Personal) and y (Valence)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_cols\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfinal_personal_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_full\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Valence_Mean'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# We train for Valence (Happiness) first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['audSpec_Rfilt_sma[17]_stddev', 'audSpec_Rfilt_sma_de[21]_stddev', 'pcm_zcr_sma_amean', 'audspec_lengthL1norm_sma_amean', 'audSpec_Rfilt_sma_de[3]_stddev', 'pcm_fftMag_fband1000-4000_sma_de_stddev', 'audSpec_Rfilt_sma[6]_stddev', 'audSpec_Rfilt_sma[8]_stddev', 'pcm_fftMag_spectralCentroid_sma_amean', 'pcm_zcr_sma_stddev', 'audSpec_Rfilt_sma_de[22]_stddev', 'audSpec_Rfilt_sma[5]_stddev', 'pcm_fftMag_spectralKurtosis_sma_amean', 'audSpec_Rfilt_sma_de[2]_stddev', 'audSpec_Rfilt_sma[5]_amean', 'audspecRasta_lengthL1norm_sma_de_stddev', 'audSpec_Rfilt_sma[18]_stddev', 'voicingFinalUnclipped_sma_de_stddev', 'audSpec_Rfilt_sma[22]_amean', 'pcm_fftMag_fband1000-4000_sma_stddev', 'logHNR_sma_de_amean', 'audSpec_Rfilt_sma_de[18]_stddev', 'jitterDDP_sma_de_amean', 'audSpec_Rfilt_sma[4]_stddev', 'shimmerLocal_sma_stddev', 'audSpec_Rfilt_sma[1]_amean', 'audSpec_Rfilt_sma_de[6]_stddev', 'pcm_fftMag_spectralRollOff25.0_sma_stddev', 'audSpec_Rfilt_sma_de[13]_stddev', 'audSpec_Rfilt_sma_de[16]_stddev', 'F0final_sma_amean', 'pcm_fftMag_fband250-650_sma_stddev', 'pcm_fftMag_spectralEntropy_sma_de_stddev', 'pcm_RMSenergy_sma_amean', 'pcm_fftMag_spectralVariance_sma_stddev', 'pcm_fftMag_spectralSlope_sma_stddev', 'pcm_fftMag_spectralRollOff90.0_sma_de_stddev', 'shimmerLocal_sma_de_stddev', 'audSpec_Rfilt_sma_de[8]_stddev', 'pcm_fftMag_spectralSkewness_sma_de_stddev', 'audSpec_Rfilt_sma[7]_amean', 'audSpec_Rfilt_sma[8]_amean', 'audSpec_Rfilt_sma_de[17]_stddev', 'pcm_fftMa..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# --- 1. SETUP ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "base_path = '/content/drive/MyDrive/TheYabancilar_Project'\n",
        "merp_path = os.path.join(base_path, 'MERP_Dataset')\n",
        "\n",
        "# --- 2. DIAGNOSTICS ---\n",
        "print(f\"Checking Base Folder: {base_path}\")\n",
        "if os.path.exists(base_path):\n",
        "    print(\"Files found:\", os.listdir(base_path))\n",
        "else:\n",
        "    print(\"âŒ Base folder not found.\")\n",
        "\n",
        "print(f\"\\nChecking MERP Folder: {merp_path}\")\n",
        "if os.path.exists(merp_path):\n",
        "    print(\"Files found:\", os.listdir(merp_path))\n",
        "else:\n",
        "    print(\"âŒ MERP folder not found.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSAhtcUTQBt-",
        "outputId": "aa8ff75f-2caa-4368-ab6b-8e2f858772d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Checking Base Folder: /content/drive/MyDrive/TheYabancilar_Project\n",
            "Files found: ['2.csv', 'MERP_Dataset', 'GlobalMood', 'GlobalMood_Dataset', 'DEAM_Phase1', 'Survey_Songs', 'Survey_OpenSMILE_Features.csv', 'Survey_OpenSMILE_Features_ComParE.csv', 'Survey_Features_Final_260.csv', 'Survey_Features_All_6373.csv', 'golden_159_features.pkl']\n",
            "\n",
            "Checking MERP Folder: /content/drive/MyDrive/TheYabancilar_Project/MERP_Dataset\n",
            "Files found: ['raw_exps.pkl', 'pinfo_numero.pkl', 'raw_audio_features.pkl', 'raw_pinfo.pkl', 'edited_audio_features.pkl', 'pinfo.pkl', 'edited_exps.pkl', 'MERP_Unified_Dataset.csv', 'songs_wav', 'MERP_Librosa_Features.csv', 'Final_Training_Data.csv', 'Final_Training_Data_Labeled.csv', 'merp_model.pkl', 'merp_scaler.pkl', 'model_columns.pkl', 'Simulated_Survey_Results.csv', 'Feature_Importance_Graph.png', 'Age_Effect_Analysis.png', 'Simulated_Survey_60.csv']\n"
          ]
        }
      ]
    }
  ]
}